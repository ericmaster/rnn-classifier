{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611706e2",
   "metadata": {},
   "source": [
    "# RNN Classifier con PyTorch Lightning\n",
    "## Trabajo Computacional 2\n",
    "\n",
    "Este notebook implementa un clasificador RNN para predecir el origen de nombres utilizando PyTorch Lightning.\n",
    "\n",
    "### Objetivos\n",
    "- Implementar un modelo RNN, LSTM y GRU para la tarea de clasificación usando PyTorch Lightning\n",
    "- Modularizar el código en componentes reutilizables:\n",
    "  - `model.py`: Definición del modelo RNN\n",
    "  - `datamodule.py`: Manejo de datos y preprocessing\n",
    "  - `train.py`: Loop de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e29155",
   "metadata": {},
   "source": [
    "## Instalación y configuración\n",
    "\n",
    "Primero instalamos las dependencias necesarias e importamos las bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daba8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PyTorch Lightning si no está instalado\n",
    "# !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e652b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu121\n",
      "PyTorch Lightning version: 2.5.3\n",
      "Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Importar módulos personalizados\n",
    "from utils.model import RNNClassifier\n",
    "from utils.datamodule import RNNDataset, RNNDataModule, n_letters\n",
    "from utils.eval import evaluate_model, plot_confusion_matrix, predict_name_origin\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n",
    "torch.manual_seed(47)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee472952",
   "metadata": {},
   "source": [
    "## Preparación de datos\n",
    "\n",
    "Descargamos y preparamos los datos de nombres si no están disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a389849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos ya están disponibles.\n"
     ]
    }
   ],
   "source": [
    "# Descargar datos si no existen\n",
    "if not os.path.exists('./data'):\n",
    "    print(\"Descargando datos...\")\n",
    "    !wget https://download.pytorch.org/tutorial/data.zip\n",
    "    !unzip data.zip\n",
    "    !rm data.zip\n",
    "    print(\"Datos descargados exitosamente!\")\n",
    "else:\n",
    "    print(\"Los datos ya están disponibles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eea7fe",
   "metadata": {},
   "source": [
    "### Distribución de datos y balanceo\n",
    "\n",
    "Al cargar e inspeccionar los datos, estos se encontraban muy desbalanceados. Para poder definir las épocas adecuadamente se hizo un sobremuestreo de las clases con menos datos y con esto tener una distribución más equitativa de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21111499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde ./data/names/...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish: 139 ejemplos\n",
      "Greek: 203 ejemplos\n",
      "Chinese: 268 ejemplos\n",
      "Scottish: 100 ejemplos\n",
      "Italian: 709 ejemplos\n",
      "German: 724 ejemplos\n",
      "Dutch: 297 ejemplos\n",
      "Arabic: 2000 ejemplos\n",
      "Portuguese: 74 ejemplos\n",
      "English: 3668 ejemplos\n",
      "Russian: 9408 ejemplos\n",
      "French: 277 ejemplos\n",
      "Czech: 519 ejemplos\n",
      "Japanese: 991 ejemplos\n",
      "Spanish: 298 ejemplos\n",
      "Korean: 94 ejemplos\n",
      "Vietnamese: 73 ejemplos\n",
      "Irish: 232 ejemplos\n",
      "\n",
      "Balanceando dataset...\n",
      "Polish - nuevo tamaño: 9313\n",
      "Greek - nuevo tamaño: 9338\n",
      "Chinese - nuevo tamaño: 9380\n",
      "Scottish - nuevo tamaño: 9400\n",
      "Italian - nuevo tamaño: 9217\n",
      "German - nuevo tamaño: 8688\n",
      "Dutch - nuevo tamaño: 9207\n",
      "Arabic - nuevo tamaño: 8000\n",
      "Portuguese - nuevo tamaño: 9398\n",
      "English - nuevo tamaño: 7336\n",
      "French - nuevo tamaño: 9141\n",
      "Czech - nuevo tamaño: 9342\n",
      "Japanese - nuevo tamaño: 8919\n",
      "Spanish - nuevo tamaño: 9238\n",
      "Korean - nuevo tamaño: 9400\n",
      "Vietnamese - nuevo tamaño: 9344\n",
      "Irish - nuevo tamaño: 9280\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "dataset = RNNDataset(data_path=\"./data/names/\", balanced=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc2bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de categorías: 18\n",
      "Categorías disponibles: ['Polish', 'Greek', 'Chinese', 'Scottish', 'Italian', 'German', 'Dutch', 'Arabic', 'Portuguese', 'English', 'Russian', 'French', 'Czech', 'Japanese', 'Spanish', 'Korean', 'Vietnamese', 'Irish']\n",
      "\n",
      "Ejemplos de entrenamiento:\n",
      "category = Czech / line = Pear\n",
      "category = Portuguese / line = Serafim\n",
      "category = Portuguese / line = Salazar\n",
      "category = Arabic / line = Khoury\n",
      "category = Greek / line = Makricosta\n"
     ]
    }
   ],
   "source": [
    "categories = dataset.categories\n",
    "\n",
    "print(f\"Número total de categorías: {len(categories)}\")\n",
    "print(f\"Categorías disponibles: {categories}\")\n",
    "\n",
    "print(f\"\\nEjemplos de entrenamiento:\")\n",
    "for i in range(5):\n",
    "    category, line, category_tensor, line_tensor = dataset.get_random_sample()\n",
    "    print(f\"category = {category} / line = {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3a492",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Ahora entrenamos el modelo RNN usando PyTorch Lightning. El entrenamiento esta dentro de un script de python separado para poder ejecutarlo fuera del kernel interactivo del presente notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f5d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento del modelo RNN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu121\n",
      "PyTorch Lightning version: 2.5.3\n",
      "Device: CUDA\n",
      "Configuración del entrenamiento:\n",
      "  hidden_size: 128\n",
      "  learning_rate: 0.00125\n",
      "  n_epochs: 100\n",
      "  batch_size: 32\n",
      "  num_workers: 40\n",
      "Probando modelo base: rnn\n",
      "Creando instancia de modelo RNN (rnn)...\n",
      "Modelo creado exitosamente!\n",
      "Arquitectura del modelo:\n",
      "  - Input size: 57 (caracteres)\n",
      "  - Hidden size: 128\n",
      "  - Output size: 18 (categorías)\n",
      "  - Learning rate: 0.00125\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Cargando modelo desde checkpoint: ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "PyTorch version: 2.3.0+cu121\n",
      "PyTorch Lightning version: 2.5.3\n",
      "Device: CUDA\n",
      "Configuración del entrenamiento:\n",
      "  hidden_size: 128\n",
      "  learning_rate: 0.00125\n",
      "  n_epochs: 100\n",
      "  batch_size: 32\n",
      "  num_workers: 40\n",
      "Probando modelo base: rnn\n",
      "Creando instancia de modelo RNN (rnn)...\n",
      "PyTorch version: 2.3.0+cu121\n",
      "PyTorch Lightning version: 2.5.3\n",
      "Device: CUDA\n",
      "Configuración del entrenamiento:\n",
      "  hidden_size: 128\n",
      "  learning_rate: 0.00125\n",
      "  n_epochs: 100\n",
      "  batch_size: 32\n",
      "  num_workers: 40\n",
      "Probando modelo base: rnn\n",
      "Creando instancia de modelo RNN (rnn)...\n",
      "PyTorch version: 2.3.0+cu121\n",
      "PyTorch Lightning version: 2.5.3\n",
      "Device: CUDA\n",
      "Configuración del entrenamiento:\n",
      "  hidden_size: 128\n",
      "  learning_rate: 0.00125\n",
      "  n_epochs: 100\n",
      "  batch_size: 32\n",
      "  num_workers: 40\n",
      "Probando modelo base: rnn\n",
      "Creando instancia de modelo RNN (rnn)...\n",
      "Modelo creado exitosamente!\n",
      "Arquitectura del modelo:\n",
      "  - Input size: 57 (caracteres)\n",
      "  - Hidden size: 128\n",
      "  - Output size: 18 (categorías)\n",
      "  - Learning rate: 0.00125\n",
      "Cargando modelo desde checkpoint: ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "Modelo creado exitosamente!\n",
      "Arquitectura del modelo:\n",
      "  - Input size: 57 (caracteres)\n",
      "  - Hidden size: 128\n",
      "  - Output size: 18 (categorías)\n",
      "  - Learning rate: 0.00125\n",
      "Modelo creado exitosamente!\n",
      "Arquitectura del modelo:\n",
      "  - Input size: 57 (caracteres)\n",
      "  - Hidden size: 128\n",
      "  - Output size: 18 (categorías)\n",
      "  - Learning rate: 0.00125\n",
      "Cargando modelo desde checkpoint: ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "Cargando modelo desde checkpoint: ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:701: Checkpoint directory /home/eaguayo/workspace/DeepLearning/rnn-classifier/checkpoints exists and is not empty.\n",
      "Restoring states from the checkpoint path at ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃   ┃ Name       ┃ Type               ┃ Params ┃ Mode  ┃\n",
      "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│ 0 │ base_model │ RNN                │ 23.9 K │ train │\n",
      "│ 1 │ out        │ Linear             │  2.3 K │ train │\n",
      "│ 2 │ softmax    │ LogSoftmax         │      0 │ train │\n",
      "│ 3 │ criterion  │ NLLLoss            │      0 │ train │\n",
      "│ 4 │ train_acc  │ MulticlassAccuracy │      0 │ train │\n",
      "│ 5 │ valid_acc  │ MulticlassAccuracy │      0 │ train │\n",
      "│ 6 │ test_acc   │ MulticlassAccuracy │      0 │ train │\n",
      "└───┴────────────┴────────────────────┴────────┴───────┘\n",
      "Trainable params: 26.3 K\n",
      "Non-trainable params: 0\n",
      "Total params: 26.3 K\n",
      "Total estimated model params size (MB): 0\n",
      "Modules in train mode: 7\n",
      "Modules in eval mode: 0\n",
      "Restored all states from the checkpoint at ./checkpoints/rnn/epoch=48-step=47187.ckpt\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('valid_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "Epoch 49/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:17 • 0:00:00 55.89it/s v_num: 10\n",
      "                                                                    valid_acc: 0.941\n",
      "Epoch 50/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.69it/s v_num: 10\n",
      "                                                                    valid_acc: 0.930\n",
      "Epoch 51/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.92it/s v_num: 10\n",
      "                                                                    valid_acc: 0.940\n",
      "Epoch 52/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.96it/s v_num: 10\n",
      "                                                                    valid_acc: 0.939\n",
      "Epoch 53/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.42it/s v_num: 10\n",
      "                                                                    valid_acc: 0.943\n",
      "Epoch 54/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:19 • 0:00:00 54.93it/s v_num: 10\n",
      "                                                                    valid_acc: 0.938\n",
      "Epoch 55/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.86it/s v_num: 10\n",
      "                                                                    valid_acc: 0.914\n",
      "Epoch 56/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.78it/s v_num: 10\n",
      "                                                                    valid_acc: 0.941\n",
      "Epoch 57/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.29it/s v_num: 10\n",
      "                                                                    valid_acc: 0.943\n",
      "Epoch 58/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.91it/s v_num: 10\n",
      "                                                                    valid_acc: 0.940\n",
      "Epoch 59/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:19 • 0:00:00 54.85it/s v_num: 10\n",
      "                                                                    valid_acc: 0.941\n",
      "Epoch 60/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.99it/s v_num: 10\n",
      "                                                                    valid_acc: 0.936\n",
      "Epoch 61/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.75it/s v_num: 10\n",
      "                                                                    valid_acc: 0.946\n",
      "Epoch 62/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.11it/s v_num: 10\n",
      "                                                                    valid_acc: 0.932\n",
      "Epoch 63/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.89it/s v_num: 10\n",
      "                                                                    valid_acc: 0.946\n",
      "Epoch 64/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:19 • 0:00:00 55.32it/s v_num: 10\n",
      "                                                                    valid_acc: 0.935\n",
      "Epoch 65/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.53it/s v_num: 10\n",
      "                                                                    valid_acc: 0.926\n",
      "Epoch 66/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.59it/s v_num: 10\n",
      "                                                                    valid_acc: 0.922\n",
      "Epoch 67/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 57.05it/s v_num: 10\n",
      "                                                                    valid_acc: 0.942\n",
      "Epoch 68/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.72it/s v_num: 10\n",
      "                                                                    valid_acc: 0.937\n",
      "Epoch 69/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:19 • 0:00:00 55.11it/s v_num: 10\n",
      "                                                                    valid_acc: 0.946\n",
      "Epoch 70/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.80it/s v_num: 10\n",
      "                                                                    valid_acc: 0.933\n",
      "Epoch 71/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.69it/s v_num: 10\n",
      "                                                                    valid_acc: 0.935\n",
      "Epoch 72/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 57.98it/s v_num: 10\n",
      "                                                                    valid_acc: 0.949\n",
      "Epoch 73/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.74it/s v_num: 10\n",
      "                                                                    valid_acc: 0.933\n",
      "Epoch 74/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.48it/s v_num: 10\n",
      "                                                                    valid_acc: 0.913\n",
      "Epoch 75/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.08it/s v_num: 10\n",
      "                                                                    valid_acc: 0.950\n",
      "Epoch 76/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:19 • 0:00:00 55.06it/s v_num: 10\n",
      "                                                                    valid_acc: 0.918\n",
      "Epoch 77/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.70it/s v_num: 10\n",
      "                                                                    valid_acc: 0.934\n",
      "Epoch 78/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 58.31it/s v_num: 10\n",
      "                                                                    valid_acc: 0.932\n",
      "Epoch 79/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 56.46it/s v_num: 10\n",
      "                                                                    valid_acc: 0.948\n",
      "Epoch 80/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 57.25it/s v_num: 10\n",
      "                                                                    valid_acc: 0.940\n",
      "Epoch 81/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.81it/s v_num: 10\n",
      "                                                                    valid_acc: 0.936\n",
      "Epoch 82/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 55.84it/s v_num: 10\n",
      "                                                                    valid_acc: 0.944\n",
      "Epoch 83/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 57.94it/s v_num: 10\n",
      "                                                                    valid_acc: 0.945\n",
      "Epoch 84/99 ━━━━━━━━━━━━━━━━━━━ 963/963 0:00:18 • 0:00:00 57.60it/s v_num: 10\n",
      "                                                                    valid_acc: 0.945\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ejecuta el script de entrenamiento usando subprocess\n",
    "script_path = \"rnn-training.py\"\n",
    "\n",
    "# Verificar que el script existe\n",
    "if not os.path.exists(script_path):\n",
    "    print(f\"Error: No se encontró el archivo {script_path}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Iniciando entrenamiento del modelo RNN...\")\n",
    "\n",
    "try:\n",
    "    # Ejecutar el script con subprocess\n",
    "    process = subprocess.Popen(\n",
    "        [sys.executable, script_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Mostrar la salida en tiempo real\n",
    "    for line in process.stdout:\n",
    "        print(line.rstrip())\n",
    "    \n",
    "    # Esperar a que termine el proceso\n",
    "    process.wait()\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(\"Entrenamiento completado exitosamente!\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Error durante el entrenamiento. Código de salida: {process.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar el script: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc3e62",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Evaluamos el modelo entrenado y visualizamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando el modelo...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0b220f29e28c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluando el modelo...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Precisión: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo (como en el original)\n",
    "print(\"Evaluando el modelo...\")\n",
    "# base_models = [\"rnn\", \"lstm\", \"gru\"]\n",
    "base_models = [\"rnn\"]  # Para simplificar, solo evaluamos el modelo RNN\n",
    "\n",
    "for base_model in base_models:\n",
    "    print(f\"\\nEvaluando modelo: {base_model.upper()}\")\n",
    "\n",
    "    # Cargar el mejor checkpoint basado en validación\n",
    "    best_checkpoint = \"./checkpoints/{base_model}/epoch=48-step=47187.ckpt\"\n",
    "    model = RNNClassifier.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        callbacks=[],\n",
    "        accelerator=\"auto\",  # Uses GPUs or TPUs if available\n",
    "        devices=\"auto\",  # Uses all available GPUs/TPUs if applicable\n",
    "        deterministic=False,\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer.test(model)\n",
    "    # accuracy, confusion_matrix, categories = evaluate_model(model, data_module, n_samples=1000)\n",
    "\n",
    "    # print(f\"Precisión: {accuracy:.4f}\")\n",
    "    # print(f\"Número de categorías: {len(categories)}\")\n",
    "\n",
    "    # # Visualizar matriz de confusión\n",
    "    # plot_confusion_matrix(confusion_matrix, categories, 'Matriz de Confusión - RNN Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a68363",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "Probamos el modelo con algunos nombres de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cee262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones del modelo:\n",
      "==================================================\n",
      "\n",
      "> Dovesky\n",
      "(-0.72) Czech\n",
      "(-0.82) Russian\n",
      "(-3.01) English\n",
      "\n",
      "\n",
      "> Jackson\n",
      "(-0.16) Scottish\n",
      "(-2.07) English\n",
      "(-4.76) Russian\n",
      "\n",
      "\n",
      "> Satoshi\n",
      "(-0.39) Japanese\n",
      "(-1.69) Italian\n",
      "(-2.68) Portuguese\n",
      "\n",
      "\n",
      "> Rodriguez\n",
      "(-0.48) Portuguese\n",
      "(-1.54) Spanish\n",
      "(-2.29) Dutch\n",
      "\n",
      "\n",
      "> Mueller\n",
      "(-0.76) Dutch\n",
      "(-1.72) Czech\n",
      "(-1.99) English\n",
      "\n",
      "\n",
      "> Li\n",
      "(-0.16) Vietnamese\n",
      "(-2.36) Korean\n",
      "(-3.03) Chinese\n",
      "\n",
      "\n",
      "> Nakamura\n",
      "(-0.01) Japanese\n",
      "(-5.60) Portuguese\n",
      "(-6.00) Arabic\n",
      "\n",
      "\n",
      "> Smith\n",
      "(-0.33) Scottish\n",
      "(-2.19) German\n",
      "(-2.92) Czech\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Probar predicciones con nombres de ejemplo\n",
    "# test_names = ['Dovesky', 'Jackson', 'Satoshi', 'Rodriguez', 'Mueller', 'Li', 'Nakamura', 'Smith']\n",
    "\n",
    "# print(\"Predicciones del modelo:\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# for name in test_names:\n",
    "#     predictions = predict_name_origin(model, name, categories, n_predictions=3)\n",
    "#     print()  # Línea en blanco entre predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa5a7",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "La implementación con PyTorch Lightning ofrece las siguientes ventajas:\n",
    "\n",
    "1. **Código más limpio y modular**: Separación clara de responsabilidades\n",
    "2. **Mejor manejo de experimentos**: Logging automático y configuración fácil\n",
    "3. **Escalabilidad**: Fácil adaptación a diferentes recursos de hardware\n",
    "4. **Reproducibilidad**: Mejor control de semillas y configuraciones\n",
    "5. **Funcionalidades avanzadas**: Early stopping, checkpointing, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91bbe8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
